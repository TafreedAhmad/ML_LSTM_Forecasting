{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "import pvlib\n",
    "from pvlib import clearsky, atmosphere, solarposition\n",
    "from pvlib.location import Location\n",
    "from pvlib.iotools import read_tmy3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHI_df = pd.DataFrame()\n",
    "years = np.linspace(2016,2021,6, dtype= int)\n",
    "file_path = './GHI_dataset/raw_data/GHI_raw_'\n",
    "\n",
    "for year in years:\n",
    "    file_path_temp = file_path + str(year) + '.csv'\n",
    "    df_temp = pd.read_csv(file_path_temp)\n",
    "    GHI_df = pd.concat([GHI_df, df_temp], axis = 0)\n",
    "\n",
    "GHI_df['datetime'] = pd.to_datetime(GHI_df['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "GHI_df.set_index('datetime', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of GHI_df measurements: \" + str(GHI_df.shape[0]))\n",
    "\n",
    "print(\"Number of NA: \" + str(GHI_df['GHI'].isnull().sum()))\n",
    "\n",
    "GHI_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Removal of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for the maximum number of consecutive missing values allowed\n",
    "threshold = 1\n",
    "\n",
    "# Identify and remove high-density consecutive missing values\n",
    "def remove_consecutive_nan(df, column, threshold):\n",
    "    bool_series = df[column].isnull()\n",
    "    df['block'] = (bool_series.diff(1) != 0).astype('int').cumsum()\n",
    "    df = df[~((df[column].isnull()) & (df.groupby('block')['block'].transform('size') > threshold))]\n",
    "    df = df.drop('block', axis=1)\n",
    "    return df\n",
    "\n",
    "GHI_df = remove_consecutive_nan(GHI_df, 'GHI', threshold)\n",
    "\n",
    "print('Number of GHI measurements to interpolate: ' + str(GHI_df['GHI'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHI_df['GHI'] = GHI_df['GHI'].interpolate()\n",
    "\n",
    "print('Number of NaNs: ' + str(GHI_df['GHI'].isnull().sum()))\n",
    "print(\"Number of GHI measurements: \" + str(GHI_df.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Identification and removal of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removal of outliers\n",
    "GHI_max = 1000\n",
    "GHI_min = 0\n",
    "\n",
    "GHI_df = GHI_df[(GHI_df[\"GHI\"] < GHI_max) & (GHI_df[\"GHI\"] > GHI_min)]\n",
    "print(\"Number of GHI measurements: \" + str(GHI_df.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Clear sky global horizontal irradiance (GHIcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear sky GHI calculation\n",
    "\n",
    "latitude = 46.518\n",
    "longitude = 6.565\n",
    "time_zone = 'Europe/Zurich'\n",
    "altitude = 400\n",
    "place = 'Ecublens'\n",
    "frequency = '10S'\n",
    "\n",
    "tus = Location(latitude, longitude, time_zone, altitude, place)\n",
    "\n",
    "cs = tus.get_clearsky(GHI_df.index)\n",
    "GHI_df['GHIcs'] = cs.ghi\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Removal of night measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Night is assumed when GHIcs is inferior to 30 W/m2\n",
    "\n",
    "nb_night_measurements = int(100*GHI_df[GHI_df['GHIcs']<30].shape[0] / GHI_df.shape[0])\n",
    "\n",
    "GHI_df = GHI_df[GHI_df[\"GHIcs\"] > 30]\n",
    "\n",
    "print(\"Percentage of GHI night measurements: \" + str(nb_night_measurements) + \"%\")\n",
    "print(\"Number of GHI measurements: \" + str(GHI_df.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Clear sky index (kcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the clear sky index - k\n",
    "\n",
    "GHI_df['k'] = GHI_df[\"GHI\"] / GHI_df[\"GHIcs\"]\n",
    "\n",
    "#Night measurement have GHIcs = 0 => k=inf ; when it happens, we set k to 0\n",
    "GHI_df.replace([np.inf, -np.inf], 0, inplace= True)\n",
    "\n",
    "GHI_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Calculation of finite-difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FirstOrderBackdDiff (serie, h):\n",
    "    y_t0 = serie.values.flatten()[1:]\n",
    "    y_t1 = serie.values.flatten()[0:-1]\n",
    "    return np.concatenate([[np.nan], (y_t0-y_t1)/(h)])\n",
    "\n",
    "def SecondOrderBackDiff (serie, h):\n",
    "    y_t0 = serie.values.flatten()[2:]\n",
    "    y_t1 = serie.values.flatten()[1:-1]\n",
    "    y_t2 = serie.values.flatten()[:-2]\n",
    "    return np.concatenate([[np.nan], [np.nan], (y_t0-2*y_t1+y_t2)/((h)**2)])\n",
    "    \n",
    "def ThirdOrderBackDiff(serie, h):\n",
    "    y_t0 = serie.values.flatten()[3:]\n",
    "    y_t1 = serie.values.flatten()[1:-2]\n",
    "    y_t2 = serie.values.flatten()[2:-1]\n",
    "    y_t3 = serie.values.flatten()[3:]\n",
    "    return np.concatenate([[np.nan], [np.nan], [np.nan], (y_t0-3*y_t1+3*y_t2-y_t3)/(h**3)])\n",
    "\n",
    "h = 10 #10s\n",
    "\n",
    "GHI_df[\"GHI_d1\"] = FirstOrderBackdDiff(GHI_df['GHI'], h)\n",
    "GHI_df[\"GHIcs_d1\"] = FirstOrderBackdDiff(GHI_df['GHIcs'], h)\n",
    "GHI_df[\"k_d1\"] = FirstOrderBackdDiff(GHI_df['k'], h)\n",
    "\n",
    "GHI_df[\"GHI_d2\"] = SecondOrderBackDiff(GHI_df['GHI'], h)\n",
    "GHI_df[\"GHIcs_d2\"] = SecondOrderBackDiff(GHI_df['GHIcs'], h)\n",
    "GHI_df[\"k_d2\"] = SecondOrderBackDiff(GHI_df['k'], h)\n",
    "\n",
    "GHI_df[\"GHI_d3\"] = ThirdOrderBackDiff(GHI_df['GHI'], h)\n",
    "GHI_df[\"GHIcs_d3\"] = ThirdOrderBackDiff(GHI_df['GHIcs'], h)\n",
    "GHI_df[\"k_d3\"] = ThirdOrderBackDiff(GHI_df['k'], h)\n",
    "\n",
    "GHI_df = GHI_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHI_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Adding seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_sin_hour(x):\n",
    "    return np.sin(x*np.pi/24)\n",
    "\n",
    "def norm_sin_day(x):\n",
    "    return np.sin(x*np.pi/365)\n",
    "\n",
    "def norm_sin_month(x):\n",
    "    return np.sin(x*np.pi/12)\n",
    "\n",
    "\n",
    "GHI_df[\"month\"] = norm_sin_month(GHI_df.index.month).copy()\n",
    "\n",
    "GHI_df[\"day\"] = norm_sin_day(GHI_df.index.dayofyear).copy()\n",
    "\n",
    "GHI_df[\"hour\"] = norm_sin_hour(GHI_df.index.hour).copy()\n",
    "\n",
    "GHI_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 - Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sampling_frequencies = [\"15T\", \"30T\", \"45T\", \"1H\", \"2H\", \n",
    "                        \"4H\", \"6H\", \"12H\", \"24H\", \"48H\", \n",
    "                        \"72H\", \"4D\", \"5D\", \"6D\", \"7D\"]\n",
    "\n",
    "sampling_frequencies_eng = [\"15_minutes\", \"30_minutes\", \"45_minutes\", \"1_hour\", \"2_hours\", \n",
    "                            \"4_hours\", \"6_hours\", \"12_hours\", \"24_hours\", \"48_hours\", \n",
    "                            \"72_hours\", \"4_days\", \"5_days\", \"6_days\", \"7_days\"]\n",
    "\n",
    "root = \"./GHI_dataset/cleaned_sampled_data/\"\n",
    "\n",
    "for i, frequency in enumerate(sampling_frequencies):\n",
    "\n",
    "    \n",
    "    df_sampled_temp = GHI_df.resample(frequency).mean().copy()\n",
    "    df_sampled_temp = df_sampled_temp.dropna()\n",
    "    df_sampled_temp.reset_index(inplace = True)\n",
    "\n",
    "    df_sampled_temp['year'] = df_sampled_temp['datetime'].dt.year\n",
    "    years = df_sampled_temp['year'].unique()\n",
    "\n",
    "    file_path= root + '/GHI_sampled_' + str(sampling_frequencies_eng[i]) + '.csv'\n",
    "    df_sampled_temp.to_csv(file_path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
