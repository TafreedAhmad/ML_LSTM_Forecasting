{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d87eacf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error, r2_score\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import multiprocessing\n",
    "matplotlib.use('Agg')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b5c1d",
   "metadata": {},
   "source": [
    "\n",
    "# DEVICE SETUP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca4daaa-f988-474b-96d6-e3db7f80a21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONTE CARLO DROPOUT LSTM\n",
      "Compute Device:           cuda\n",
      "GPU Model:                NVIDIA GeForce RTX 5060 Ti\n",
      "GPU Memory:               8.55 GB\n",
      "CPU Cores:                20\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_workers = min(8, multiprocessing.cpu_count() - 1)\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "\n",
    "print(f\"MONTE CARLO DROPOUT LSTM\")\n",
    "\n",
    "print(f\"Compute Device:           {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Model:                {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory:               {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"CPU Cores:                {multiprocessing.cpu_count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b27fe60-3162-45b4-b188-7f3aabf09d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabbcdb9",
   "metadata": {},
   "source": [
    "\n",
    "# LSTM MODEL WITH DROPOUT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2a8df92d-1496-4438-a79b-9173fcd4fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropoutLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=300, num_layers=3, dropout_rate=0.2):\n",
    "        super(MCDropoutLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # lstm layers with dropout\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.lstm3 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x, use_dropout=True):\n",
    "        out, _ = self.lstm1(x)\n",
    "        if use_dropout:\n",
    "            out = self.dropout1(out)\n",
    "        \n",
    "        out, _ = self.lstm2(out)\n",
    "        if use_dropout:\n",
    "            out = self.dropout2(out)\n",
    "        \n",
    "        out, _ = self.lstm3(out)\n",
    "        if use_dropout:\n",
    "            out = self.dropout3(out)\n",
    "        \n",
    "        out = out[:, -1, :]  \n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a64db5",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a2ece28-d88d-411e-b952-eceee2c5e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def MBE(y_ref, y_test):\n",
    "    return np.sum(y_test - y_ref) / len(y_ref)\n",
    "\n",
    "\n",
    "def invTransform(scaler, data, colName, colNames):\n",
    "    dummy = pd.DataFrame(np.zeros((len(data), len(colNames))), columns=colNames)\n",
    "    dummy[colName] = data\n",
    "    dummy = pd.DataFrame(scaler.inverse_transform(dummy), columns=colNames)\n",
    "    return dummy[colName].values\n",
    "\n",
    "\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0\n",
    "\n",
    "\n",
    "def calculate_quantile_metrics(y_true, y_pred_p10, y_pred_p50, y_pred_p90):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred_p10 = np.array(y_pred_p10)\n",
    "    y_pred_p50 = np.array(y_pred_p50)\n",
    "    y_pred_p90 = np.array(y_pred_p90)\n",
    "    \n",
    "    coverage_80 = np.mean((y_true >= y_pred_p10) & (y_true <= y_pred_p90)) * 100\n",
    "    interval_width = np.mean(y_pred_p90 - y_pred_p10)\n",
    "    pinaw = interval_width / (np.mean(y_true) + 1e-8)\n",
    "    \n",
    "    def quantile_loss(y_true, y_pred, quantile):\n",
    "        error = y_true - y_pred\n",
    "        return np.mean(np.maximum(quantile * error, (quantile - 1) * error))\n",
    "    \n",
    "    ql_p10 = quantile_loss(y_true, y_pred_p10, 0.1)\n",
    "    ql_p50 = quantile_loss(y_true, y_pred_p50, 0.5)\n",
    "    ql_p90 = quantile_loss(y_true, y_pred_p90, 0.9)\n",
    "    \n",
    "    return {\n",
    "        'PICP_80': coverage_80,\n",
    "        'PINAW': pinaw,\n",
    "        'QuantileLoss_P10': ql_p10,\n",
    "        'QuantileLoss_P50': ql_p50,\n",
    "        'QuantileLoss_P90': ql_p90,\n",
    "        'AvgQuantileScore': (ql_p10 + ql_p50 + ql_p90) / 3,\n",
    "        'IntervalWidth': interval_width\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "579c8938-c94b-4bbd-b9ac-bac26651472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                num_epochs=50, patience=10, verbose=True):\n",
    "    \"\"\"model with early stopping and progress tracking\"\"\"\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': [], 'epoch': []}\n",
    "    \n",
    "    epoch_pbar = tqdm(range(num_epochs), desc=\"Training\", disable=not verbose)\n",
    "    \n",
    "    for epoch in epoch_pbar:\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x, use_dropout=True)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_x, use_dropout=False)  \n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        history['epoch'].append(epoch + 1)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        # progress bar\n",
    "        epoch_pbar.set_postfix({\n",
    "            'train': f'{train_loss:.6f}',\n",
    "            'val': f'{val_loss:.6f}',\n",
    "            'best_val': f'{best_val_loss:.6f}',\n",
    "            'patience': f'{patience_counter}/{patience}'\n",
    "        })\n",
    "        \n",
    "        # early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\n Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # restore best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, len(history['epoch']), history\n",
    "\n",
    "\n",
    "def mc_dropout_predict(model, data_loader, n_samples=100, verbose=True):\n",
    "    model.train()  \n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    sample_pbar = tqdm(range(n_samples), desc=\"MC Sampling\", disable=not verbose, leave=False)\n",
    "    \n",
    "    for _ in sample_pbar:\n",
    "        batch_predictions = []\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for batch_x, _ in data_loader:\n",
    "                batch_x = batch_x.to(device)\n",
    "                outputs = model(batch_x, use_dropout=True)\n",
    "                batch_predictions.append(outputs.cpu().numpy())\n",
    "        \n",
    "        all_predictions.append(np.vstack(batch_predictions))\n",
    "    \n",
    "    return np.array(all_predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77e18170-db29-41e8-82d4-67eaf4af6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curve(history, save_path):\n",
    "    \"\"\" training and validation loss\"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    ax.plot(history['epoch'], history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "    ax.plot(history['epoch'], history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Loss (MSE)', fontsize=12)\n",
    "    ax.set_title('Training Progress', fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_mc_predictions(y_true, pred_p10, pred_p50, pred_p90, mc_samples, save_path):\n",
    "    \"\"\" MC Dropout predictions with uncertainty\"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "    fig.suptitle('Monte Carlo Dropout Predictions', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    n_plot = min(200, len(y_true))\n",
    "    idx = np.arange(n_plot)\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.plot(idx, y_true[:n_plot], 'k-', label='Actual', linewidth=2, alpha=0.8)\n",
    "    ax.plot(idx, pred_p50[:n_plot], 'b-', label='P50 (Median)', linewidth=1.5)\n",
    "    ax.fill_between(idx, pred_p10[:n_plot], pred_p90[:n_plot], \n",
    "                     alpha=0.3, color='blue', label='P10-P90 Interval (80%)')\n",
    "    \n",
    "    outside = (y_true[:n_plot] < pred_p10[:n_plot]) | (y_true[:n_plot] > pred_p90[:n_plot])\n",
    "    if outside.sum() > 0:\n",
    "        ax.scatter(idx[outside], y_true[:n_plot][outside], \n",
    "                  color='red', s=50, marker='x', label='Outside Interval', zorder=5)\n",
    "    \n",
    "    ax.set_xlabel('Sample Index')\n",
    "    ax.set_ylabel('GHI (W/m²)')\n",
    "    ax.set_title(f'Predictions with Uncertainty (first {n_plot} samples)')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax = axes[1]\n",
    "    n_show = min(20, mc_samples.shape[0])\n",
    "    sample_indices = np.random.choice(mc_samples.shape[0], n_show, replace=False)\n",
    "    \n",
    "    for i in sample_indices:\n",
    "        ax.plot(idx, mc_samples[i, :n_plot, 0], alpha=0.3, linewidth=0.8, color='gray')\n",
    "    \n",
    "    ax.plot(idx, y_true[:n_plot], 'k-', label='Actual', linewidth=2, alpha=0.8)\n",
    "    ax.plot(idx, pred_p50[:n_plot], 'r-', label='Median', linewidth=2)\n",
    "    ax.set_xlabel('Sample Index')\n",
    "    ax.set_ylabel('GHI (W/m²)')\n",
    "    ax.set_title(f'MC Dropout Samples (showing {n_show} of 100 stochastic passes)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax = axes[2]\n",
    "    ax2 = ax.twinx()\n",
    "    \n",
    "    interval_width = (pred_p90 - pred_p10)[:n_plot]\n",
    "    residuals = y_true[:n_plot] - pred_p50[:n_plot]\n",
    "    \n",
    "    ax.plot(idx, residuals, 'b-', alpha=0.6, label='Residuals', linewidth=1.5)\n",
    "    ax.axhline(y=0, color='k', linestyle='--', linewidth=1)\n",
    "    ax2.plot(idx, interval_width, 'r-', alpha=0.6, linewidth=1.5, label='Interval Width')\n",
    "    \n",
    "    ax.set_xlabel('Sample Index')\n",
    "    ax.set_ylabel('Residual (W/m²)', color='b')\n",
    "    ax2.set_ylabel('Interval Width (W/m²)', color='r')\n",
    "    ax.set_title('Prediction Error vs Uncertainty')\n",
    "    ax.tick_params(axis='y', labelcolor='b')\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_coverage_analysis(y_true, pred_p10, pred_p50, pred_p90, save_path):\n",
    "    \"\"\"Plot coverage analysis\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle('Coverage & Calibration Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    in_interval = (y_true >= pred_p10) & (y_true <= pred_p90)\n",
    "    interval_width = pred_p90 - pred_p10\n",
    "    coverage = in_interval.mean() * 100\n",
    "    \n",
    "    ax = axes[0, 0]\n",
    "    bins = np.percentile(y_true, [0, 20, 40, 60, 80, 100])\n",
    "    digitized = np.digitize(y_true, bins)\n",
    "    coverage_by_bin = [in_interval[digitized == i].mean() * 100 for i in range(1, len(bins))]\n",
    "    x_labels = [f'{bins[i]:.0f}-{bins[i+1]:.0f}' for i in range(len(bins)-1)]\n",
    "    \n",
    "    bars = ax.bar(range(len(coverage_by_bin)), coverage_by_bin, alpha=0.7)\n",
    "    ax.axhline(y=80, color='red', linestyle='--', linewidth=2, label='Target (80%)')\n",
    "    ax.set_xlabel('GHI Range (W/m²)')\n",
    "    ax.set_ylabel('Coverage (%)')\n",
    "    ax.set_title('Coverage by Value Range')\n",
    "    ax.set_xticks(range(len(coverage_by_bin)))\n",
    "    ax.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for i, bar in enumerate(bars):\n",
    "        if 75 <= coverage_by_bin[i] <= 85:\n",
    "            bar.set_color('green')\n",
    "        elif coverage_by_bin[i] < 70:\n",
    "            bar.set_color('red')\n",
    "        else:\n",
    "            bar.set_color('orange')\n",
    "    \n",
    "    ax = axes[0, 1]\n",
    "    ax.hist(interval_width, bins=50, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(x=interval_width.mean(), color='red', linestyle='--', \n",
    "               linewidth=2, label=f'Mean: {interval_width.mean():.1f}')\n",
    "    ax.set_xlabel('Interval Width (W/m²)')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Distribution of Uncertainty')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    ax = axes[1, 0]\n",
    "    scatter = ax.scatter(y_true, interval_width, c=in_interval, \n",
    "                        cmap='RdYlGn', alpha=0.5, s=10)\n",
    "    ax.set_xlabel('Actual GHI (W/m²)')\n",
    "    ax.set_ylabel('Interval Width (W/m²)')\n",
    "    ax.set_title('Interval Width vs Actual Value')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax, label='In Interval')\n",
    "    \n",
    "    ax = axes[1, 1]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    below_p10 = (y_true < pred_p10).sum()\n",
    "    above_p90 = (y_true > pred_p90).sum()\n",
    "    \n",
    "    summary = f\"\"\"Overall Coverage:     {coverage:.2f}%\"\"\"\n",
    "    \n",
    "    ax.text(0.05, 0.5, summary, fontsize=10, family='monospace',\n",
    "            verticalalignment='center', transform=ax.transAxes,\n",
    "            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4cf351",
   "metadata": {},
   "source": [
    "# CONFIGURATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad9a0c81-3e1b-4fed-a301-2d06f325c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbEpoch = 50\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "patience = 10\n",
    "mc_samples = 100  \n",
    "dropout_rate = 0.2\n",
    "\n",
    "\n",
    "#just key time horizons\n",
    "nPrevSteps_list = [10, 20] \n",
    "\n",
    "\n",
    "polynomialAugm_list = [1, 2]  \n",
    "\n",
    "samplingFrequencies_eng = [\"15_minutes\", \"30_minutes\", \"1_hour\"] \n",
    "\n",
    "basicFeatures = ['GHI', 'GHIcs', 'k']\n",
    "seasonalFeatures = ['month', 'day', 'hour']\n",
    "d1Features = ['GHI_d1', 'GHIcs_d1', 'k_d1']\n",
    "d2Features = ['GHI_d2', 'GHIcs_d2', 'k_d2']\n",
    "\n",
    "\n",
    "featureColumns_list = [\n",
    "    basicFeatures,                           \n",
    "    basicFeatures + d1Features,             \n",
    "    basicFeatures + seasonalFeatures,        \n",
    "    basicFeatures + seasonalFeatures + d1Features \n",
    "]\n",
    "\n",
    "featureColumns_eng_list = ['GHI', 'GHI_d1', 'GHI_season', 'GHI_season_d1']\n",
    "\n",
    "\n",
    "data_dir = './GHI_dataset/cleaned_sampled_data/'\n",
    "reportLSTM_dir = './reports/LSTM_mcdropout/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a5c95",
   "metadata": {},
   "source": [
    "# MAIN LOOP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "850db800-eb94-4500-b179-5ff64b7cf660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configurations: 48\n",
      "\n",
      "================================================================================\n",
      "Frequency: 15_minutes (1/3)\n",
      "================================================================================\n",
      "Loaded: 85620 samples\n",
      "\n",
      "Features: GHI (1/4)\n",
      "  [1/48] Poly=1, Hist=10 | ETA: 0.2min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 49/50 [05:14<00:06,  6.41s/it, train=0.004495, val=0.004149, best_val=0.004088, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 50\n",
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [2/48] Poly=1, Hist=20 | ETA: 222.3min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 48/50 [05:44<00:14,  7.17s/it, train=0.004750, val=0.004387, best_val=0.004252, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 49\n",
      " Model trained (49 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [3/48] Poly=2, Hist=10 | ETA: 304.1min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 35/50 [03:46<01:37,  6.48s/it, train=0.004526, val=0.004457, best_val=0.004088, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 36\n",
      " Model trained (36 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [4/48] Poly=2, Hist=20 | ETA: 313.2min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [05:48<00:00,  6.97s/it, train=0.004697, val=0.004658, best_val=0.004361, patience=3/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "\n",
      "Features: GHI_d1 (2/4)\n",
      "  [5/48] Poly=1, Hist=10 | ETA: 333.2min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 40/50 [04:21<01:05,  6.55s/it, train=0.004460, val=0.004135, best_val=0.004101, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 41\n",
      " Model trained (41 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [6/48] Poly=1, Hist=20 | ETA: 332.8min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 36/50 [04:18<01:40,  7.17s/it, train=0.004998, val=0.004409, best_val=0.004404, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 37\n",
      " Model trained (37 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [7/48] Poly=2, Hist=10 | ETA: 329.7min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 26/50 [02:52<02:38,  6.62s/it, train=0.004479, val=0.004127, best_val=0.004057, patience=9/10]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 27\n",
      " Model trained (27 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [8/48] Poly=2, Hist=20 | ETA: 318.0min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|███████████████████████████████████████████████████████████████████████████▏                                                                                                       | 21/50 [02:33<03:32,  7.33s/it, train=0.004803, val=0.005475, best_val=0.005019, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 22\n",
      " Model trained (22 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "\n",
      "Features: GHI_season (3/4)\n",
      "  [9/48] Poly=1, Hist=10 | ETA: 306.2min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███████████████████████████████████▊                                                                                                                                               | 10/50 [01:09<04:36,  6.92s/it, train=0.010357, val=0.016371, best_val=0.007422, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 11\n",
      " Model trained (11 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [10/48] Poly=1, Hist=20 | ETA: 289.6min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|███████████████████████████████████████▍                                                                                                                                           | 11/50 [01:24<05:00,  7.72s/it, train=0.008775, val=0.014094, best_val=0.008099, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 12\n",
      " Model trained (12 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [11/48] Poly=2, Hist=10 | ETA: 276.3min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|██████████████████████████████████████████████████████████████████████████████████▎                                                                                                | 23/50 [02:35<03:02,  6.76s/it, train=0.007796, val=0.008719, best_val=0.005228, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 24\n",
      " Model trained (24 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [12/48] Poly=2, Hist=20 | ETA: 267.7min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|████████████████████████████████████████████████████████████▊                                                                                                                      | 17/50 [02:05<04:03,  7.38s/it, train=0.007486, val=0.011273, best_val=0.007095, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 18\n",
      " Model trained (18 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "\n",
      "Features: GHI_season_d1 (4/4)\n",
      "  [13/48] Poly=1, Hist=10 | ETA: 258.0min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███████████████████████████████████▊                                                                                                                                               | 10/50 [01:09<04:37,  6.94s/it, train=0.013555, val=0.015525, best_val=0.011119, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 11\n",
      " Model trained (11 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [14/48] Poly=1, Hist=20 | ETA: 246.2min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███████████████████████████████████▊                                                                                                                                               | 10/50 [01:16<05:06,  7.66s/it, train=0.011447, val=0.016530, best_val=0.010846, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 11\n",
      " Model trained (11 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [15/48] Poly=2, Hist=10 | ETA: 235.6min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|███████████████████████████████████▊                                                                                                                                               | 10/50 [01:09<04:37,  6.95s/it, train=0.009388, val=0.011005, best_val=0.009209, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 11\n",
      " Model trained (11 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [16/48] Poly=2, Hist=20 | ETA: 225.8min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██████████████████████████████████████████████████                                                                                                                                 | 14/50 [01:56<04:58,  8.29s/it, train=0.008568, val=0.014924, best_val=0.008774, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 15\n",
      " Model trained (15 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "\n",
      "Summary saved: summary_mcdropout_15_minutes.csv\n",
      "Overview plot saved: overview_15_minutes.png\n",
      "\n",
      "================================================================================\n",
      "Frequency: 30_minutes (2/3)\n",
      "================================================================================\n",
      "Loaded: 43897 samples\n",
      "\n",
      "Features: GHI (1/4)\n",
      "  [17/48] Poly=1, Hist=10 | ETA: 218.6min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|██████████████████████████████████████████████████████████████████████████████████▎                                                                                                | 23/50 [02:31<02:57,  6.57s/it, train=0.008500, val=0.007612, best_val=0.007275, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 24\n",
      " Model trained (24 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [18/48] Poly=1, Hist=20 | ETA: 211.9min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██████████████████████████████████████████▉                                                                                                                                        | 12/50 [01:27<04:36,  7.28s/it, train=0.011422, val=0.010997, best_val=0.009259, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 13\n",
      " Model trained (13 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [19/48] Poly=2, Hist=10 | ETA: 203.4min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [05:07<00:00,  6.14s/it, train=0.006338, val=0.006662, best_val=0.005923, patience=4/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [20/48] Poly=2, Hist=20 | ETA: 200.3min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                         | 25/50 [02:48<02:48,  6.72s/it, train=0.013428, val=0.011406, best_val=0.007467, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 26\n",
      " Model trained (26 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "\n",
      "Features: GHI_d1 (2/4)\n",
      "  [21/48] Poly=1, Hist=10 | ETA: 193.5min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [05:07<00:00,  6.15s/it, train=0.006769, val=0.006491, best_val=0.006424, patience=0/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [22/48] Poly=1, Hist=20 | ETA: 189.4min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                              | 28/50 [03:07<02:27,  6.71s/it, train=0.007246, val=0.007607, best_val=0.007091, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 29\n",
      " Model trained (29 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [23/48] Poly=2, Hist=10 | ETA: 182.6min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [05:09<00:00,  6.19s/it, train=0.006430, val=0.006031, best_val=0.006136, patience=0/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [24/48] Poly=2, Hist=20 | ETA: 177.9min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|████████████████████████████████████████████████████████████▊                                                                                                                      | 17/50 [01:56<03:46,  6.87s/it, train=0.008284, val=0.008790, best_val=0.007592, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 18\n",
      " Model trained (18 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "\n",
      "Features: GHI_season (3/4)\n",
      "  [25/48] Poly=1, Hist=10 | ETA: 169.7min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|███████████████████████████████████████████████████████████████████████████▏                                                                                                       | 21/50 [02:15<03:07,  6.45s/it, train=0.009246, val=0.009122, best_val=0.007685, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 22\n",
      " Model trained (22 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [26/48] Poly=1, Hist=20 | ETA: 161.9min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██████████████████████████████████████████▉                                                                                                                                        | 12/50 [01:23<04:25,  7.00s/it, train=0.010346, val=0.011224, best_val=0.011128, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 13\n",
      " Model trained (13 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [27/48] Poly=2, Hist=10 | ETA: 153.5min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|█████████████████████████████████████████████████████████▎                                                                                                                         | 16/50 [01:44<03:42,  6.54s/it, train=0.010399, val=0.010005, best_val=0.007061, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 17\n",
      " Model trained (17 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [28/48] Poly=2, Hist=20 | ETA: 145.6min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 40/50 [04:25<01:06,  6.65s/it, train=0.006783, val=0.006740, best_val=0.006566, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 41\n",
      " Model trained (41 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "\n",
      "Features: GHI_season_d1 (4/4)\n",
      "  [29/48] Poly=1, Hist=10 | ETA: 139.5min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|████████████████████████████████████████████████████████████████████                                                                                                               | 19/50 [02:02<03:19,  6.45s/it, train=0.007343, val=0.009553, best_val=0.006856, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 20\n",
      " Model trained (20 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [30/48] Poly=1, Hist=20 | ETA: 131.8min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [05:23<00:00,  6.47s/it, train=0.005946, val=0.006473, best_val=0.005790, patience=5/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [31/48] Poly=2, Hist=10 | ETA: 125.9min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 27/50 [02:51<02:26,  6.37s/it, train=0.006048, val=0.007473, best_val=0.006364, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 28\n",
      " Model trained (28 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [32/48] Poly=2, Hist=20 | ETA: 118.6min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 43/50 [04:45<00:46,  6.64s/it, train=0.006185, val=0.006376, best_val=0.005976, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 44\n",
      " Model trained (44 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "\n",
      "Summary saved: summary_mcdropout_30_minutes.csv\n",
      "Overview plot saved: overview_30_minutes.png\n",
      "\n",
      "================================================================================\n",
      "Frequency: 1_hour (3/3)\n",
      "================================================================================\n",
      "Loaded: 23138 samples\n",
      "\n",
      "Features: GHI (1/4)\n",
      "  [33/48] Poly=1, Hist=10 | ETA: 112.1min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 40/50 [03:58<00:59,  5.95s/it, train=0.009167, val=0.005968, best_val=0.005651, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 41\n",
      " Model trained (41 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [34/48] Poly=1, Hist=20 | ETA: 105.1min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 43/50 [04:22<00:42,  6.10s/it, train=0.009745, val=0.009367, best_val=0.006142, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 44\n",
      " Model trained (44 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [35/48] Poly=2, Hist=10 | ETA: 98.1min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:49<00:00,  5.80s/it, train=0.007325, val=0.006174, best_val=0.005316, patience=0/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [36/48] Poly=2, Hist=20 | ETA: 91.2min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:58<00:00,  5.97s/it, train=0.007358, val=0.005451, best_val=0.005536, patience=8/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "\n",
      "Features: GHI_d1 (2/4)\n",
      "  [37/48] Poly=1, Hist=10 | ETA: 84.2min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:49<00:00,  5.79s/it, train=0.007264, val=0.005619, best_val=0.005359, patience=2/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [38/48] Poly=1, Hist=20 | ETA: 77.0min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:58<00:00,  5.97s/it, train=0.009011, val=0.006720, best_val=0.005961, patience=6/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [39/48] Poly=2, Hist=10 | ETA: 69.8min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                           | 38/50 [03:45<01:11,  5.93s/it, train=0.008143, val=0.006634, best_val=0.005631, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 39\n",
      " Model trained (39 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [40/48] Poly=2, Hist=20 | ETA: 62.1min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:59<00:00,  5.98s/it, train=0.009709, val=0.007288, best_val=0.005483, patience=3/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "\n",
      "Features: GHI_season (3/4)\n",
      "  [41/48] Poly=1, Hist=10 | ETA: 54.7min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:50<00:00,  5.80s/it, train=0.009692, val=0.007331, best_val=0.005474, patience=0/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [42/48] Poly=1, Hist=20 | ETA: 47.1min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 42/50 [04:16<00:48,  6.11s/it, train=0.008196, val=0.006117, best_val=0.005836, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 43\n",
      " Model trained (43 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [43/48] Poly=2, Hist=10 | ETA: 39.4min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:49<00:00,  5.78s/it, train=0.008102, val=0.005875, best_val=0.005205, patience=0/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [44/48] Poly=2, Hist=20 | ETA: 31.6min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:59<00:00,  6.00s/it, train=0.009202, val=0.008611, best_val=0.005372, patience=5/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "\n",
      "Features: GHI_season_d1 (4/4)\n",
      "  [45/48] Poly=1, Hist=10 | ETA: 23.9min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 36/50 [03:34<01:23,  5.96s/it, train=0.008401, val=0.005870, best_val=0.005845, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 37\n",
      " Model trained (37 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [46/48] Poly=1, Hist=20 | ETA: 15.9min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋              | 46/50 [04:39<00:24,  6.08s/it, train=0.009707, val=0.006975, best_val=0.006968, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 47\n",
      " Model trained (47 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [47/48] Poly=2, Hist=10 | ETA: 8.0min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:49<00:00,  5.80s/it, train=0.008174, val=0.006802, best_val=0.005270, patience=5/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "  [48/48] Poly=2, Hist=20 | ETA: 0.0min\n",
      "\n",
      " Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:59<00:00,  5.98s/it, train=0.010775, val=0.006297, best_val=0.005834, patience=5/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained (50 epochs)\n",
      "   Training plot saved\n",
      "\n",
      " Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC sampling complete\n",
      " Prediction plot saved\n",
      "  Coverage plot saved\n",
      "\n",
      "Summary saved: summary_mcdropout_1_hour.csv\n",
      "Overview plot saved: overview_1_hour.png\n",
      "\n",
      "================================================================================\n",
      "TRAINING COMPLETE\n",
      "================================================================================\n",
      "Total time: 394.4 minutes (6.57 hours)\n",
      " Results: ./reports/LSTM_mcdropout/\n"
     ]
    }
   ],
   "source": [
    "total_configs = len(samplingFrequencies_eng) * len(featureColumns_list) * len(polynomialAugm_list) * len(nPrevSteps_list)\n",
    "current_config = 0\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Total configurations: {total_configs}\")\n",
    "\n",
    "for freq_idx, samplingFrequency in enumerate(samplingFrequencies_eng):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Frequency: {samplingFrequency} ({freq_idx+1}/{len(samplingFrequencies_eng)})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    report_dir = os.path.join(reportLSTM_dir, samplingFrequency)\n",
    "    models_dir = os.path.join(report_dir, 'models')\n",
    "    plots_dir = os.path.join(report_dir, 'plots')\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(data_dir, f'GHI_sampled_{samplingFrequency}.csv')\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    data_df = pd.read_csv(file_path, index_col=0)\n",
    "    print(f\"Loaded: {data_df.shape[0]} samples\")\n",
    "    \n",
    "    summary_results = []\n",
    "    \n",
    "    for k, featureColumns in enumerate(featureColumns_list):\n",
    "        print(f\"\\nFeatures: {featureColumns_eng_list[k]} ({k+1}/{len(featureColumns_list)})\")\n",
    "        \n",
    "        for polynomialAug in polynomialAugm_list:\n",
    "            for nPrevSteps in nPrevSteps_list:\n",
    "                current_config += 1\n",
    "                elapsed = time.time() - start_time\n",
    "                eta = (elapsed / current_config) * (total_configs - current_config)\n",
    "                \n",
    "                print(f\"  [{current_config}/{total_configs}] Poly={polynomialAug}, Hist={nPrevSteps} | ETA: {eta/60:.1f}min\")\n",
    "\n",
    "                \n",
    "                set_seed(42)\n",
    "                X = data_df.loc[:, featureColumns]\n",
    "                \n",
    "                poly = PolynomialFeatures(polynomialAug)\n",
    "                X_poly = poly.fit_transform(X)\n",
    "                colNames = poly.get_feature_names_out(X.columns)\n",
    "                \n",
    "                scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "                scaled = scaler.fit_transform(X_poly)\n",
    "                scaled = pd.DataFrame(scaled, columns=colNames, index=data_df.index)\n",
    "                scaled = scaled.drop(\"1\", axis=1)\n",
    "                nFeatureColumns = scaled.shape[1]\n",
    "                \n",
    "                train_test_df = pd.DataFrame()\n",
    "                for i in range(nPrevSteps + 1):\n",
    "                    title = scaled.columns + 't(-' + str(i) + ')'\n",
    "                    temp = scaled.shift(periods=i)\n",
    "                    temp.columns = title\n",
    "                    train_test_df = pd.concat([train_test_df, temp], axis=1)\n",
    "                \n",
    "                train_test_df = train_test_df.dropna()\n",
    "                \n",
    "                title_0 = scaled.columns + 't(-' + str(0) + ')'\n",
    "                X = train_test_df.drop(title_0, axis=1).values\n",
    "                y = train_test_df['GHIt(-0)'].values.reshape(-1, 1)\n",
    "                \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "                X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=False)\n",
    "                \n",
    "                X_train_r = X_train.reshape((X_train.shape[0], nPrevSteps, nFeatureColumns))\n",
    "                X_val_r = X_val.reshape((X_val.shape[0], nPrevSteps, nFeatureColumns))\n",
    "                X_test_r = X_test.reshape((X_test.shape[0], nPrevSteps, nFeatureColumns))\n",
    "                \n",
    "                train_dataset = TensorDataset(torch.FloatTensor(X_train_r), torch.FloatTensor(y_train))\n",
    "                val_dataset = TensorDataset(torch.FloatTensor(X_val_r), torch.FloatTensor(y_val))\n",
    "                test_dataset = TensorDataset(torch.FloatTensor(X_test_r), torch.FloatTensor(y_test))\n",
    "                \n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                         num_workers=num_workers, pin_memory=True if torch.cuda.is_available() else False)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                       num_workers=num_workers, pin_memory=True if torch.cuda.is_available() else False)\n",
    "                test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                        num_workers=num_workers, pin_memory=True if torch.cuda.is_available() else False)\n",
    "                \n",
    "                # TRAIN MODEL\n",
    "                print(f\"\\n Training MC Dropout model...\")\n",
    "                \n",
    "                model = MCDropoutLSTM(\n",
    "                    input_size=nFeatureColumns,\n",
    "                    hidden_size=300,\n",
    "                    num_layers=3,\n",
    "                    dropout_rate=dropout_rate\n",
    "                ).to(device)\n",
    "                \n",
    "                criterion = nn.MSELoss()\n",
    "                optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                \n",
    "                model, epochs_trained, history = train_model(\n",
    "                    model, train_loader, val_loader,\n",
    "                    criterion, optimizer, nbEpoch, patience, verbose=True\n",
    "                )\n",
    "                \n",
    "                print(f\" Model trained ({epochs_trained} epochs)\")\n",
    "                \n",
    "                # Save model\n",
    "                model_filename = f'model_{samplingFrequency}_{featureColumns_eng_list[k]}_P{polynomialAug}_H{nPrevSteps}.pt'\n",
    "                model_path = os.path.join(models_dir, model_filename)\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'input_size': nFeatureColumns,\n",
    "                    'hidden_size': 300,\n",
    "                    'dropout_rate': dropout_rate,\n",
    "                    'epochs_trained': epochs_trained,\n",
    "                    'history': history\n",
    "                }, model_path)\n",
    "                \n",
    "                plot_filename = f'training_{samplingFrequency}_{featureColumns_eng_list[k]}_P{polynomialAug}_H{nPrevSteps}.png'\n",
    "                plot_path = os.path.join(plots_dir, plot_filename)\n",
    "                plot_training_curve(history, plot_path)\n",
    "                print(f\"   Training plot saved\")\n",
    "                \n",
    "                print(f\"\\n Performing MC Dropout sampling ({mc_samples} passes)...\")\n",
    "                \n",
    "                \n",
    "                mc_predictions_scaled = mc_dropout_predict(model, test_loader, n_samples=mc_samples, verbose=True)\n",
    "                \n",
    "                \n",
    "                y_pred_p10_scaled = np.percentile(mc_predictions_scaled, 10, axis=0)\n",
    "                y_pred_p50_scaled = np.percentile(mc_predictions_scaled, 50, axis=0)\n",
    "                y_pred_p90_scaled = np.percentile(mc_predictions_scaled, 90, axis=0)\n",
    "                \n",
    "                \n",
    "                pred_p10 = invTransform(scaler, y_pred_p10_scaled, 'GHI', colNames)\n",
    "                pred_p50 = invTransform(scaler, y_pred_p50_scaled, 'GHI', colNames)\n",
    "                pred_p90 = invTransform(scaler, y_pred_p90_scaled, 'GHI', colNames)\n",
    "                test = invTransform(scaler, y_test, 'GHI', colNames)\n",
    "                \n",
    "               \n",
    "                mc_samples_inv = np.zeros_like(mc_predictions_scaled)\n",
    "                for i in range(mc_samples):\n",
    "                    mc_samples_inv[i] = invTransform(scaler, mc_predictions_scaled[i], 'GHI', colNames).reshape(-1, 1)\n",
    "                \n",
    "                print(f\"MC sampling complete\")\n",
    "                \n",
    "         \n",
    "                MAPE_P50 = calculate_mape(test, pred_p50)\n",
    "                RMSE_P50 = np.sqrt(mean_squared_error(test, pred_p50))\n",
    "                nRMSE_P50 = RMSE_P50 / (np.mean(test) + 1e-8)\n",
    "                MAE_P50 = mean_absolute_error(test, pred_p50)\n",
    "                nMAE_P50 = MAE_P50 / (np.mean(test) + 1e-8)\n",
    "                R2_P50 = r2_score(test, pred_p50)\n",
    "                MBE_P50 = MBE(test, pred_p50)\n",
    "                \n",
    "                quantile_metrics = calculate_quantile_metrics(test, pred_p10, pred_p50, pred_p90)\n",
    "\n",
    "                \n",
    "\n",
    "                plot_filename = f'predictions_{samplingFrequency}_{featureColumns_eng_list[k]}_P{polynomialAug}_H{nPrevSteps}.png'\n",
    "                plot_path = os.path.join(plots_dir, plot_filename)\n",
    "                plot_mc_predictions(test, pred_p10, pred_p50, pred_p90, mc_samples_inv, plot_path)\n",
    "                print(f\" Prediction plot saved\")\n",
    "  \n",
    "                plot_filename = f'coverage_{samplingFrequency}_{featureColumns_eng_list[k]}_P{polynomialAug}_H{nPrevSteps}.png'\n",
    "                plot_path = os.path.join(plots_dir, plot_filename)\n",
    "                plot_coverage_analysis(test, pred_p10, pred_p50, pred_p90, plot_path)\n",
    "                print(f\"  Coverage plot saved\")\n",
    "                \n",
    "     \n",
    "                quantile_predictions_df = pd.DataFrame({\n",
    "                    'y_true': test,\n",
    "                    'y_pred_p10': pred_p10,\n",
    "                    'y_pred_p50': pred_p50,\n",
    "                    'y_pred_p90': pred_p90,\n",
    "                    'interval_width': pred_p90 - pred_p10,\n",
    "                    'in_interval': (test >= pred_p10) & (test <= pred_p90)\n",
    "                })\n",
    "                \n",
    "                quantile_pred_filename = f'quantile_predictions_{samplingFrequency}_{featureColumns_eng_list[k]}_P{polynomialAug}_H{nPrevSteps}.csv'\n",
    "                quantile_pred_path = os.path.join(report_dir, quantile_pred_filename)\n",
    "                quantile_predictions_df.to_csv(quantile_pred_path, index=False)\n",
    "        \n",
    "                summary_results.append({\n",
    "                    'samplingFrequency': samplingFrequency,\n",
    "                    'polynomialAugmentation': polynomialAug,\n",
    "                    'features': featureColumns_eng_list[k],\n",
    "                    'history': nPrevSteps,\n",
    "                    'epochs_trained': epochs_trained,\n",
    "                    'dropout_rate': dropout_rate,\n",
    "                    'mc_samples': mc_samples,\n",
    "                    'MAPE_P50': MAPE_P50,\n",
    "                    'RMSE_P50': RMSE_P50,\n",
    "                    'nRMSE_P50': nRMSE_P50,\n",
    "                    'MAE_P50': MAE_P50,\n",
    "                    'nMAE_P50': nMAE_P50,\n",
    "                    'R2_P50': R2_P50,\n",
    "                    'MBE_P50': MBE_P50,\n",
    "                    'PICP_80': quantile_metrics['PICP_80'],\n",
    "                    'PINAW': quantile_metrics['PINAW'],\n",
    "                    'QuantileLoss_P10': quantile_metrics['QuantileLoss_P10'],\n",
    "                    'QuantileLoss_P50': quantile_metrics['QuantileLoss_P50'],\n",
    "                    'QuantileLoss_P90': quantile_metrics['QuantileLoss_P90'],\n",
    "                    'AvgQuantileScore': quantile_metrics['AvgQuantileScore'],\n",
    "                    'IntervalWidth': quantile_metrics['IntervalWidth']\n",
    "                })\n",
    "                \n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "    if len(summary_results) > 0:\n",
    "        summary_df = pd.DataFrame(summary_results)\n",
    "        summary_filename = f'summary_mcdropout_{samplingFrequency}.csv'\n",
    "        summary_path = os.path.join(report_dir, summary_filename)\n",
    "        summary_df.to_csv(summary_path, index=False)\n",
    "        print(f\"\\nSummary saved: {summary_filename}\")\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "        fig.suptitle(f'MC Dropout Performance Overview: {samplingFrequency}', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        picp_values = summary_df['PICP_80'].values\n",
    "        mape_values = summary_df['MAPE_P50'].values\n",
    "        interval_values = summary_df['IntervalWidth'].values\n",
    "        \n",
    "        # Graphs\n",
    "        ax = axes[0, 0]\n",
    "        ax.hist(picp_values, bins=20, alpha=0.7, edgecolor='black', color='steelblue')\n",
    "        ax.axvline(x=80, color='red', linestyle='--', linewidth=2, label='Target (80%)')\n",
    "        ax.axvline(x=picp_values.mean(), color='green', linestyle='--', linewidth=2, \n",
    "                  label=f'Mean ({picp_values.mean():.1f}%)')\n",
    "        ax.axvspan(75, 85, alpha=0.2, color='green', label='Good Range')\n",
    "        ax.set_xlabel('PICP (%)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title('Coverage Distribution')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "        ax = axes[0, 1]\n",
    "        scatter = ax.scatter(mape_values, picp_values, alpha=0.6, s=100, \n",
    "                           c=interval_values, cmap='viridis')\n",
    "        ax.axhline(y=80, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "        ax.axhspan(75, 85, alpha=0.1, color='green')\n",
    "        ax.set_xlabel('MAPE (%)')\n",
    "        ax.set_ylabel('PICP (%)')\n",
    "        ax.set_title('Accuracy vs Coverage Trade-off')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        cbar = plt.colorbar(scatter, ax=ax)\n",
    "        cbar.set_label('Interval Width (W/m²)', rotation=270, labelpad=20)\n",
    "        \n",
    "\n",
    "        ax = axes[1, 0]\n",
    "        ax.hist(interval_values, bins=20, alpha=0.7, edgecolor='black', color='coral')\n",
    "        ax.axvline(x=interval_values.mean(), color='red', linestyle='--', \n",
    "                  linewidth=2, label=f'Mean: {interval_values.mean():.1f} W/m²')\n",
    "        ax.set_xlabel('Average Interval Width (W/m²)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title('Uncertainty Distribution')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "        ax = axes[1, 1]\n",
    "        ax.axis('off')\n",
    "\n",
    "        summary_df['coverage_error'] = np.abs(summary_df['PICP_80'] - 80)\n",
    "        summary_df_sorted = summary_df.sort_values('coverage_error')\n",
    "        \n",
    "        best_text = \"Top 5 configs\\n\"\n",
    "        best_text += \"=\"*55 + \"\\n\\n\"\n",
    "        \n",
    "        for idx, (_, row) in enumerate(summary_df_sorted.head(5).iterrows(), 1):\n",
    "            best_text += f\"{idx}. {row['features']}, \"\n",
    "            best_text += f\"Poly={int(row['polynomialAugmentation'])}, \"\n",
    "            best_text += f\"Hist={int(row['history'])}\\n\"\n",
    "            best_text += f\"   PICP: {row['PICP_80']:.1f}%  |  \"\n",
    "            best_text += f\"MAPE: {row['MAPE_P50']:.2f}%  |  \"\n",
    "            best_text += f\"Width: {row['IntervalWidth']:.1f}\\n\\n\"\n",
    "        \n",
    "        best_text += \"\\n\" + \"=\"*55 + \"\\n\"\n",
    "        best_text += f\"Overall Statistics:\\n\"\n",
    "        best_text += f\"  Avg Coverage: {picp_values.mean():.1f}% ± {picp_values.std():.1f}%\\n\"\n",
    "        best_text += f\"  Avg MAPE:     {mape_values.mean():.2f}% ± {mape_values.std():.2f}%\\n\"\n",
    "        best_text += f\"  Configs in 75-85%: {((picp_values >= 75) & (picp_values <= 85)).sum()}/{len(picp_values)}\\n\"\n",
    "        \n",
    "        ax.text(0.05, 0.5, best_text, fontsize=9, family='monospace',\n",
    "               verticalalignment='center', transform=ax.transAxes,\n",
    "               bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        overview_path = os.path.join(report_dir, f'overview_{samplingFrequency}.png')\n",
    "        plt.savefig(overview_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Overview plot saved: overview_{samplingFrequency}.png\")\n",
    "\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total time: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
    "print(f\" Results: {reportLSTM_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cabc85d-c4a8-4b1d-aa86-1fcda69833d8",
   "metadata": {},
   "source": [
    "# Results are okayish but the model is overfitting so we are trying with some other dropout   \n",
    "\n",
    "## Target: Get PICP to 70-85% range\n",
    "-> Validate Calibration:\n",
    "Once we have ~75-85% coverage, we will verify if it's consistent:\n",
    "\n",
    "Check coverage across different GHI ranges (low/medium/high irradiance)\n",
    "Check coverage across seasons (winter vs summer)\n",
    "Ensure intervals aren't just uniformly wider everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27acc28a",
   "metadata": {},
   "source": [
    "# CONFIGURATION - CHANGES HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39050f93-dc27-4fd4-8305-b748d846fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbEpoch = 50\n",
    "batch_size = 512  \n",
    "learning_rate = 0.001  \n",
    "patience = 10\n",
    "mc_samples = 100\n",
    "dropout_rate = 0.35  \n",
    "num_workers = 4  \n",
    "\n",
    "nPrevSteps_list = [10, 20]  \n",
    "polynomialAugm_list = [1, 2] \n",
    "samplingFrequencies_eng = [\"15_minutes\"]  \n",
    "\n",
    "\n",
    "featureColumns_list = [\n",
    "    basicFeatures,                           \n",
    "    basicFeatures + d1Features,              \n",
    "    basicFeatures + seasonalFeatures + d1Features  \n",
    "]\n",
    "featureColumns_eng_list = ['GHI', 'GHI_d1', 'GHI_season_d1']  \n",
    "\n",
    "\n",
    "reportLSTM_dir = './reports2/LSTM_mcdropout_calibrated/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd8d1c4e-7e8c-44e5-9aa0-83f97cde8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                num_epochs=50, patience=10, verbose=True):\n",
    "    \"\"\"early stopping and progress tracking\"\"\"\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': [], 'epoch': []}\n",
    "    \n",
    "    use_amp = torch.cuda.is_available()\n",
    "    if use_amp:\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    epoch_pbar = tqdm(range(num_epochs), desc=\"Training\", disable=not verbose)\n",
    "    \n",
    "    for epoch in epoch_pbar:\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device, non_blocking=True), batch_y.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(batch_x, use_dropout=True)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(batch_x, use_dropout=True)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_x, use_dropout=False)  \n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        history['epoch'].append(epoch + 1)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "   \n",
    "        epoch_pbar.set_postfix({\n",
    "            'train': f'{train_loss:.6f}',\n",
    "            'val': f'{val_loss:.6f}',\n",
    "            'best_val': f'{best_val_loss:.6f}',\n",
    "            'patience': f'{patience_counter}/{patience}'\n",
    "        })\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\n Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, len(history['epoch']), history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92451363-a7fc-4292-86f2-4af01dde2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict(model, data_loader, n_samples=100, verbose=True):\n",
    "    model.train() \n",
    "    first_batch = next(iter(data_loader))\n",
    "    n_test = sum(len(batch_y) for _, batch_y in data_loader)\n",
    "    \n",
    "    all_predictions = torch.zeros(n_samples, n_test, 1, device=device)\n",
    "    \n",
    "    sample_pbar = tqdm(range(n_samples), desc=\"MC Sampling\", disable=not verbose, leave=False)\n",
    "    \n",
    "    for sample_idx in sample_pbar:\n",
    "        batch_start = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_x, _ in data_loader:\n",
    "                batch_x = batch_x.to(device, non_blocking=True)\n",
    "                batch_size = batch_x.size(0)\n",
    "                \n",
    "                outputs = model(batch_x, use_dropout=True)\n",
    "                all_predictions[sample_idx, batch_start:batch_start+batch_size] = outputs\n",
    "                \n",
    "                batch_start += batch_size\n",
    "    \n",
    "    return all_predictions.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9040e3e3-65ea-4a5e-bece-931af100a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropoutLSTM(nn.Module):\n",
    "    \"\"\"aggressive dropout for better uncertainty calibration\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=300, num_layers=3, dropout_rate=0.35):  \n",
    "        super(MCDropoutLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.lstm3 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.dropout_fc = nn.Dropout(dropout_rate * 0.8) \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x, use_dropout=True):\n",
    "        out, _ = self.lstm1(x)\n",
    "        if use_dropout:\n",
    "            out = self.dropout1(out)\n",
    "        \n",
    "        out, _ = self.lstm2(out)\n",
    "        if use_dropout:\n",
    "            out = self.dropout2(out)\n",
    "        \n",
    "        out, _ = self.lstm3(out)\n",
    "        if use_dropout:\n",
    "            out = self.dropout3(out)\n",
    "        \n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        if use_dropout:\n",
    "            out = self.dropout_fc(out)\n",
    "            \n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "967b49bd-ab57-4c2f-a3a8-627ba7e7a506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configurations: 12\n",
      "Started: 2025-11-29 09:34:41\n",
      "Training 1 model per config (vs 10 for ensemble) → 10x faster!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Frequency: 15_minutes (1/1)\n",
      "================================================================================\n",
      " Loaded: 85620 samples\n",
      "\n",
      "Features: GHI (1/3)\n",
      "\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "[1/12] Poly=1, Hist=10 | ETA: 0.1min\n",
      "  ────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                            | 0/50 [00:00<?, ?it/s]C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:23<00:00,  5.26s/it, train=0.004739, val=0.004131, best_val=0.004165, patience=2/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained (50 epochs)\n",
      "Training plot saved\n",
      "\n",
      "Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MC sampling complete\n",
      " Prediction plot saved\n",
      " Coverage plot saved\n",
      "\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "[2/12] Poly=1, Hist=20 | ETA: 41.1min\n",
      "  ────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                            | 0/50 [00:00<?, ?it/s]C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training:  78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 39/50 [03:43<01:03,  5.73s/it, train=0.006937, val=0.005893, best_val=0.005249, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 40\n",
      "Model trained (40 epochs)\n",
      "Training plot saved\n",
      "\n",
      "Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MC sampling complete\n",
      " Prediction plot saved\n",
      " Coverage plot saved\n",
      "\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "[3/12] Poly=2, Hist=10 | ETA: 47.4min\n",
      "  ────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                            | 0/50 [00:00<?, ?it/s]C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:23<00:00,  5.27s/it, train=0.004710, val=0.004101, best_val=0.004087, patience=4/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained (50 epochs)\n",
      "Training plot saved\n",
      "\n",
      "Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MC sampling complete\n",
      " Prediction plot saved\n",
      " Coverage plot saved\n",
      "\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "[4/12] Poly=2, Hist=20 | ETA: 48.1min\n",
      "  ────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                            | 0/50 [00:00<?, ?it/s]C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:39<00:00,  5.60s/it, train=0.005464, val=0.004557, best_val=0.004541, patience=0/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained (50 epochs)\n",
      "Training plot saved\n",
      "\n",
      "Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MC sampling complete\n",
      " Prediction plot saved\n",
      " Coverage plot saved\n",
      "\n",
      "Features: GHI_d1 (2/3)\n",
      "\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "[5/12] Poly=1, Hist=10 | ETA: 45.6min\n",
      "  ────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                            | 0/50 [00:00<?, ?it/s]C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:23<00:00,  5.27s/it, train=0.004781, val=0.004112, best_val=0.004112, patience=3/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained (50 epochs)\n",
      "Training plot saved\n",
      "\n",
      "Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MC sampling complete\n",
      " Prediction plot saved\n",
      " Coverage plot saved\n",
      "\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "[6/12] Poly=1, Hist=20 | ETA: 40.8min\n",
      "  ────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                            | 0/50 [00:00<?, ?it/s]C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 36/50 [03:27<01:20,  5.78s/it, train=0.006761, val=0.005786, best_val=0.005022, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 37\n",
      "Model trained (37 epochs)\n",
      "Training plot saved\n",
      "\n",
      "Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MC sampling complete\n",
      " Prediction plot saved\n",
      " Coverage plot saved\n",
      "\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "[7/12] Poly=2, Hist=10 | ETA: 34.4min\n",
      "  ────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                            | 0/50 [00:00<?, ?it/s]C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:22<00:00,  5.26s/it, train=0.004698, val=0.004045, best_val=0.004027, patience=3/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained (50 epochs)\n",
      "Training plot saved\n",
      "\n",
      "Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MC sampling complete\n",
      " Prediction plot saved\n",
      " Coverage plot saved\n",
      "\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "[8/12] Poly=2, Hist=20 | ETA: 28.2min\n",
      "  ────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                            | 0/50 [00:00<?, ?it/s]C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training:  22%|███████████████████████████████████████▍                                                                                                                                           | 11/50 [01:06<03:56,  6.06s/it, train=0.070977, val=0.053565, best_val=0.025862, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 12\n",
      "Model trained (12 epochs)\n",
      "Training plot saved\n",
      "\n",
      "Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MC sampling complete\n",
      " Prediction plot saved\n",
      " Coverage plot saved\n",
      "\n",
      "Features: GHI_season_d1 (3/3)\n",
      "\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "[9/12] Poly=1, Hist=10 | ETA: 20.5min\n",
      "  ────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                            | 0/50 [00:00<?, ?it/s]C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training:  66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                            | 33/50 [02:58<01:31,  5.41s/it, train=0.007057, val=0.007313, best_val=0.004739, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 34\n",
      "Model trained (34 epochs)\n",
      "Training plot saved\n",
      "\n",
      "Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MC sampling complete\n",
      " Prediction plot saved\n",
      " Coverage plot saved\n",
      "\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "[10/12] Poly=1, Hist=20 | ETA: 13.7min\n",
      "  ────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                            | 0/50 [00:00<?, ?it/s]C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 49/50 [04:39<00:05,  5.71s/it, train=0.006731, val=0.006685, best_val=0.004862, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 50\n",
      "Model trained (50 epochs)\n",
      "Training plot saved\n",
      "\n",
      "Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MC sampling complete\n",
      " Prediction plot saved\n",
      " Coverage plot saved\n",
      "\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "[11/12] Poly=2, Hist=10 | ETA: 7.0min\n",
      "  ────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                            | 0/50 [00:00<?, ?it/s]C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training:  52%|█████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 26/50 [02:23<02:12,  5.52s/it, train=0.007864, val=0.005135, best_val=0.005082, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 27\n",
      "Model trained (27 epochs)\n",
      "Training plot saved\n",
      "\n",
      "Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MC sampling complete\n",
      " Prediction plot saved\n",
      " Coverage plot saved\n",
      "\n",
      "  ────────────────────────────────────────────────────────────────────────────\n",
      "[12/12] Poly=2, Hist=20 | ETA: 0.0min\n",
      "  ────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Dropout model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                            | 0/50 [00:00<?, ?it/s]C:\\Users\\atafr\\AppData\\Local\\Temp\\ipykernel_40308\\1284388874.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training:  62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 31/50 [03:00<01:50,  5.84s/it, train=0.006592, val=0.006118, best_val=0.004465, patience=9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early stopping at epoch 32\n",
      "Model trained (32 epochs)\n",
      "Training plot saved\n",
      "\n",
      "Performing MC Dropout sampling (100 passes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MC sampling complete\n",
      " Prediction plot saved\n",
      " Coverage plot saved\n",
      "\n",
      "Summary saved: summary_mcdropout_15_minutes.csv\n",
      "Overview plot saved: overview_15_minutes.png\n",
      "\n",
      "================================================================================\n",
      "MC DROPOUT changed training complete\n",
      "================================================================================\n",
      "Total time: 90.3 minutes (1.51 hours)\n",
      " Results: ./reports2/LSTM_mcdropout_calibrated/\n"
     ]
    }
   ],
   "source": [
    "total_configs = len(samplingFrequencies_eng) * len(featureColumns_list) * len(polynomialAugm_list) * len(nPrevSteps_list)\n",
    "current_config = 0\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Total configurations: {total_configs}\")\n",
    "print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Training 1 model per config (vs 10 for ensemble) → 10x faster!\\n\")\n",
    "\n",
    "for freq_idx, samplingFrequency in enumerate(samplingFrequencies_eng):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Frequency: {samplingFrequency} ({freq_idx+1}/{len(samplingFrequencies_eng)})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    report_dir = os.path.join(reportLSTM_dir, samplingFrequency)\n",
    "    models_dir = os.path.join(report_dir, 'models')\n",
    "    plots_dir = os.path.join(report_dir, 'plots')\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(data_dir, f'GHI_sampled_{samplingFrequency}.csv')\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    data_df = pd.read_csv(file_path, index_col=0)\n",
    "    print(f\" Loaded: {data_df.shape[0]} samples\")\n",
    "    \n",
    "    summary_results = []\n",
    "    \n",
    "    for k, featureColumns in enumerate(featureColumns_list):\n",
    "        print(f\"\\nFeatures: {featureColumns_eng_list[k]} ({k+1}/{len(featureColumns_list)})\")\n",
    "        \n",
    "        for polynomialAug in polynomialAugm_list:\n",
    "            for nPrevSteps in nPrevSteps_list:\n",
    "                current_config += 1\n",
    "                elapsed = time.time() - start_time\n",
    "                eta = (elapsed / current_config) * (total_configs - current_config)\n",
    "                \n",
    "                print(f\"\\n  {'─'*76}\")\n",
    "                print(f\"[{current_config}/{total_configs}] Poly={polynomialAug}, Hist={nPrevSteps} | ETA: {eta/60:.1f}min\")\n",
    "                print(f\"  {'─'*76}\")\n",
    "                \n",
    "                set_seed(42)\n",
    "                X = data_df.loc[:, featureColumns]\n",
    "                \n",
    "                poly = PolynomialFeatures(polynomialAug)\n",
    "                X_poly = poly.fit_transform(X)\n",
    "                colNames = poly.get_feature_names_out(X.columns)\n",
    "                \n",
    "                scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "                scaled = scaler.fit_transform(X_poly)\n",
    "                scaled = pd.DataFrame(scaled, columns=colNames, index=data_df.index)\n",
    "                scaled = scaled.drop(\"1\", axis=1)\n",
    "                nFeatureColumns = scaled.shape[1]\n",
    "                \n",
    "                train_test_df = pd.DataFrame()\n",
    "                for i in range(nPrevSteps + 1):\n",
    "                    title = scaled.columns + 't(-' + str(i) + ')'\n",
    "                    temp = scaled.shift(periods=i)\n",
    "                    temp.columns = title\n",
    "                    train_test_df = pd.concat([train_test_df, temp], axis=1)\n",
    "                \n",
    "                train_test_df = train_test_df.dropna()\n",
    "                \n",
    "                title_0 = scaled.columns + 't(-' + str(0) + ')'\n",
    "                X = train_test_df.drop(title_0, axis=1).values\n",
    "                y = train_test_df['GHIt(-0)'].values.reshape(-1, 1)\n",
    "                \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "                X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=False)\n",
    "                \n",
    "                X_train_r = X_train.reshape((X_train.shape[0], nPrevSteps, nFeatureColumns))\n",
    "                X_val_r = X_val.reshape((X_val.shape[0], nPrevSteps, nFeatureColumns))\n",
    "                X_test_r = X_test.reshape((X_test.shape[0], nPrevSteps, nFeatureColumns))\n",
    "                \n",
    "                train_dataset = TensorDataset(torch.FloatTensor(X_train_r), torch.FloatTensor(y_train))\n",
    "                val_dataset = TensorDataset(torch.FloatTensor(X_val_r), torch.FloatTensor(y_val))\n",
    "                test_dataset = TensorDataset(torch.FloatTensor(X_test_r), torch.FloatTensor(y_test))\n",
    "                \n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                         num_workers=num_workers, pin_memory=True)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                       num_workers=num_workers, pin_memory=True)\n",
    "                test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                        num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "                # Train\n",
    "                print(f\"\\nTraining MC Dropout model...\")\n",
    "                \n",
    "                model = MCDropoutLSTM(\n",
    "                    input_size=nFeatureColumns,\n",
    "                    hidden_size=300,\n",
    "                    num_layers=3,\n",
    "                    dropout_rate=dropout_rate\n",
    "                ).to(device)\n",
    "                \n",
    "                criterion = nn.MSELoss()\n",
    "                optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                \n",
    "                model, epochs_trained, history = train_model(\n",
    "                    model, train_loader, val_loader,\n",
    "                    criterion, optimizer, nbEpoch, patience, verbose=True\n",
    "                )\n",
    "                \n",
    "                print(f\"Model trained ({epochs_trained} epochs)\")\n",
    "                \n",
    "                # Save model\n",
    "                model_filename = f'model_{samplingFrequency}_{featureColumns_eng_list[k]}_P{polynomialAug}_H{nPrevSteps}.pt'\n",
    "                model_path = os.path.join(models_dir, model_filename)\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'input_size': nFeatureColumns,\n",
    "                    'hidden_size': 300,\n",
    "                    'dropout_rate': dropout_rate,\n",
    "                    'epochs_trained': epochs_trained,\n",
    "                    'history': history\n",
    "                }, model_path)\n",
    "                \n",
    "                plot_filename = f'training_{samplingFrequency}_{featureColumns_eng_list[k]}_P{polynomialAug}_H{nPrevSteps}.png'\n",
    "                plot_path = os.path.join(plots_dir, plot_filename)\n",
    "                plot_training_curve(history, plot_path)\n",
    "                print(f\"Training plot saved\")\n",
    "                \n",
    "\n",
    "                print(f\"\\nPerforming MC Dropout sampling ({mc_samples} passes)...\")\n",
    "                \n",
    "            \n",
    "                mc_predictions_scaled = mc_dropout_predict(model, test_loader, n_samples=mc_samples, verbose=True)\n",
    "                \n",
    "         \n",
    "                y_pred_p10_scaled = np.percentile(mc_predictions_scaled, 10, axis=0)\n",
    "                y_pred_p50_scaled = np.percentile(mc_predictions_scaled, 50, axis=0)\n",
    "                y_pred_p90_scaled = np.percentile(mc_predictions_scaled, 90, axis=0)\n",
    "   \n",
    "                pred_p10 = invTransform(scaler, y_pred_p10_scaled, 'GHI', colNames)\n",
    "                pred_p50 = invTransform(scaler, y_pred_p50_scaled, 'GHI', colNames)\n",
    "                pred_p90 = invTransform(scaler, y_pred_p90_scaled, 'GHI', colNames)\n",
    "                test = invTransform(scaler, y_test, 'GHI', colNames)\n",
    "\n",
    "                mc_samples_inv = np.zeros_like(mc_predictions_scaled)\n",
    "                for i in range(mc_samples):\n",
    "                    mc_samples_inv[i] = invTransform(scaler, mc_predictions_scaled[i], 'GHI', colNames).reshape(-1, 1)\n",
    "                \n",
    "                print(f\" MC sampling complete\")\n",
    "                \n",
    "                MAPE_P50 = calculate_mape(test, pred_p50)\n",
    "                RMSE_P50 = np.sqrt(mean_squared_error(test, pred_p50))\n",
    "                nRMSE_P50 = RMSE_P50 / (np.mean(test) + 1e-8)\n",
    "                MAE_P50 = mean_absolute_error(test, pred_p50)\n",
    "                nMAE_P50 = MAE_P50 / (np.mean(test) + 1e-8)\n",
    "                R2_P50 = r2_score(test, pred_p50)\n",
    "                MBE_P50 = MBE(test, pred_p50)\n",
    "                \n",
    "                quantile_metrics = calculate_quantile_metrics(test, pred_p10, pred_p50, pred_p90)\n",
    "                \n",
    "      \n",
    "                \n",
    "                plot_filename = f'predictions_{samplingFrequency}_{featureColumns_eng_list[k]}_P{polynomialAug}_H{nPrevSteps}.png'\n",
    "                plot_path = os.path.join(plots_dir, plot_filename)\n",
    "                plot_mc_predictions(test, pred_p10, pred_p50, pred_p90, mc_samples_inv, plot_path)\n",
    "                print(f\" Prediction plot saved\")\n",
    "\n",
    "                plot_filename = f'coverage_{samplingFrequency}_{featureColumns_eng_list[k]}_P{polynomialAug}_H{nPrevSteps}.png'\n",
    "                plot_path = os.path.join(plots_dir, plot_filename)\n",
    "                plot_coverage_analysis(test, pred_p10, pred_p50, pred_p90, plot_path)\n",
    "                print(f\" Coverage plot saved\")\n",
    "                \n",
    "                quantile_predictions_df = pd.DataFrame({\n",
    "                    'y_true': test,\n",
    "                    'y_pred_p10': pred_p10,\n",
    "                    'y_pred_p50': pred_p50,\n",
    "                    'y_pred_p90': pred_p90,\n",
    "                    'interval_width': pred_p90 - pred_p10,\n",
    "                    'in_interval': (test >= pred_p10) & (test <= pred_p90)\n",
    "                })\n",
    "                \n",
    "                quantile_pred_filename = f'quantile_predictions_{samplingFrequency}_{featureColumns_eng_list[k]}_P{polynomialAug}_H{nPrevSteps}.csv'\n",
    "                quantile_pred_path = os.path.join(report_dir, quantile_pred_filename)\n",
    "                quantile_predictions_df.to_csv(quantile_pred_path, index=False)\n",
    "                \n",
    "                summary_results.append({\n",
    "                    'samplingFrequency': samplingFrequency,\n",
    "                    'polynomialAugmentation': polynomialAug,\n",
    "                    'features': featureColumns_eng_list[k],\n",
    "                    'history': nPrevSteps,\n",
    "                    'epochs_trained': epochs_trained,\n",
    "                    'dropout_rate': dropout_rate,\n",
    "                    'mc_samples': mc_samples,\n",
    "                    'MAPE_P50': MAPE_P50,\n",
    "                    'RMSE_P50': RMSE_P50,\n",
    "                    'nRMSE_P50': nRMSE_P50,\n",
    "                    'MAE_P50': MAE_P50,\n",
    "                    'nMAE_P50': nMAE_P50,\n",
    "                    'R2_P50': R2_P50,\n",
    "                    'MBE_P50': MBE_P50,\n",
    "                    'PICP_80': quantile_metrics['PICP_80'],\n",
    "                    'PINAW': quantile_metrics['PINAW'],\n",
    "                    'QuantileLoss_P10': quantile_metrics['QuantileLoss_P10'],\n",
    "                    'QuantileLoss_P50': quantile_metrics['QuantileLoss_P50'],\n",
    "                    'QuantileLoss_P90': quantile_metrics['QuantileLoss_P90'],\n",
    "                    'AvgQuantileScore': quantile_metrics['AvgQuantileScore'],\n",
    "                    'IntervalWidth': quantile_metrics['IntervalWidth']\n",
    "                })\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "    if len(summary_results) > 0:\n",
    "        summary_df = pd.DataFrame(summary_results)\n",
    "        summary_filename = f'summary_mcdropout_{samplingFrequency}.csv'\n",
    "        summary_path = os.path.join(report_dir, summary_filename)\n",
    "        summary_df.to_csv(summary_path, index=False)\n",
    "        print(f\"\\nSummary saved: {summary_filename}\")\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "        fig.suptitle(f'MC Dropout Performance Overview: {samplingFrequency}', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        picp_values = summary_df['PICP_80'].values\n",
    "        mape_values = summary_df['MAPE_P50'].values\n",
    "        interval_values = summary_df['IntervalWidth'].values\n",
    "\n",
    "        ax = axes[0, 0]\n",
    "        ax.hist(picp_values, bins=20, alpha=0.7, edgecolor='black', color='steelblue')\n",
    "        ax.axvline(x=80, color='red', linestyle='--', linewidth=2, label='Target (80%)')\n",
    "        ax.axvline(x=picp_values.mean(), color='green', linestyle='--', linewidth=2, \n",
    "                  label=f'Mean ({picp_values.mean():.1f}%)')\n",
    "        ax.axvspan(75, 85, alpha=0.2, color='green', label='Good Range')\n",
    "        ax.set_xlabel('PICP (%)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title('Coverage Distribution')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "\n",
    "        ax = axes[0, 1]\n",
    "        scatter = ax.scatter(mape_values, picp_values, alpha=0.6, s=100, \n",
    "                           c=interval_values, cmap='viridis')\n",
    "        ax.axhline(y=80, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "        ax.axhspan(75, 85, alpha=0.1, color='green')\n",
    "        ax.set_xlabel('MAPE (%)')\n",
    "        ax.set_ylabel('PICP (%)')\n",
    "        ax.set_title('Accuracy vs Coverage Trade-off')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        cbar = plt.colorbar(scatter, ax=ax)\n",
    "        cbar.set_label('Interval Width (W/m²)', rotation=270, labelpad=20)\n",
    "        \n",
    "        ax = axes[1, 0]\n",
    "        ax.hist(interval_values, bins=20, alpha=0.7, edgecolor='black', color='coral')\n",
    "        ax.axvline(x=interval_values.mean(), color='red', linestyle='--', \n",
    "                  linewidth=2, label=f'Mean: {interval_values.mean():.1f} W/m²')\n",
    "        ax.set_xlabel('Average Interval Width (W/m²)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title('Uncertainty Distribution')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        ax = axes[1, 1]\n",
    "        ax.axis('off')\n",
    "        \n",
    "        summary_df['coverage_error'] = np.abs(summary_df['PICP_80'] - 80)\n",
    "        summary_df_sorted = summary_df.sort_values('coverage_error')\n",
    "        \n",
    "        best_text = \"TOP 5 CONFIGURATIONS\\n\"\n",
    "        best_text += \"=\"*55 + \"\\n\\n\"\n",
    "        \n",
    "        for idx, (_, row) in enumerate(summary_df_sorted.head(5).iterrows(), 1):\n",
    "            best_text += f\"{idx}. {row['features']}, \"\n",
    "            best_text += f\"Poly={int(row['polynomialAugmentation'])}, \"\n",
    "            best_text += f\"Hist={int(row['history'])}\\n\"\n",
    "            best_text += f\"   PICP: {row['PICP_80']:.1f}%  |  \"\n",
    "            best_text += f\"MAPE: {row['MAPE_P50']:.2f}%  |  \"\n",
    "            best_text += f\"Width: {row['IntervalWidth']:.1f}\\n\\n\"\n",
    "        \n",
    "        best_text += \"\\n\" + \"=\"*55 + \"\\n\"\n",
    "        best_text += f\"Overall Statistics:\\n\"\n",
    "        best_text += f\"  Avg Coverage: {picp_values.mean():.1f}% ± {picp_values.std():.1f}%\\n\"\n",
    "        best_text += f\"  Avg MAPE:     {mape_values.mean():.2f}% ± {mape_values.std():.2f}%\\n\"\n",
    "        best_text += f\"  Configs in 75-85%: {((picp_values >= 75) & (picp_values <= 85)).sum()}/{len(picp_values)}\\n\"\n",
    "        \n",
    "        ax.text(0.05, 0.5, best_text, fontsize=9, family='monospace',\n",
    "               verticalalignment='center', transform=ax.transAxes,\n",
    "               bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        overview_path = os.path.join(report_dir, f'overview_{samplingFrequency}.png')\n",
    "        plt.savefig(overview_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Overview plot saved: overview_{samplingFrequency}.png\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MC DROPOUT changed training complete\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total time: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
    "print(f\" Results: {reportLSTM_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0544c-6983-4784-ae61-08be2c484ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7a3891-d409-473f-b9c5-cf508e5c2b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e1380-cd1f-4875-8aa3-afe3d015ed1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118d71b-5b90-4a6d-9f8c-34eb0214f8b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e37523-47d3-4b6b-9b1e-8f4ac4abd645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LSTM CPU)",
   "language": "python",
   "name": "lstm_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
